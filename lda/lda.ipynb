{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/research/edubot/repo/edubot/utils/')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of data with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will infer the different topics of questions using LDA topic modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23838"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have a pre-loaded file with all the questions.\n",
    "file = open(utils.data_path+'lda/questions.txt', 'r')\n",
    "questions = file.readlines()\n",
    "file.close()\n",
    "len(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi, I am <<FULLNAME>> <<FULLNAME>>.  I am a retired medical worker living in East Tennessee near the Smokey Mountains.  I have an abiding interest in all things spiritual and psychological.  I am also an InterFaith minister, that never really practiced that profession except among my friends.  A close friend is also doing this course for her social worker credits which is how I found out about it.  I like doing online courses where the participants share their experiences in an online group like this.  Looking forward to getting to know you all. Love and blessings,  CRose\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list of tokenized and stemmed questions, also removing stop-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_texts = [utils.tokenize_and_stem(question) for question in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'fullnam',\n",
       " 'fullnam',\n",
       " 'retir',\n",
       " 'medic',\n",
       " 'worker',\n",
       " 'live',\n",
       " 'east',\n",
       " 'tennesse',\n",
       " 'near',\n",
       " 'smokey',\n",
       " 'mountain',\n",
       " 'abid',\n",
       " 'interest',\n",
       " 'thing',\n",
       " 'spiritu',\n",
       " 'psycholog',\n",
       " 'also',\n",
       " 'interfaith',\n",
       " 'minist',\n",
       " 'never',\n",
       " 'realli',\n",
       " 'practic',\n",
       " 'profess',\n",
       " 'except',\n",
       " 'among',\n",
       " 'friend',\n",
       " 'close',\n",
       " 'friend',\n",
       " 'also',\n",
       " 'cours',\n",
       " 'social',\n",
       " 'worker',\n",
       " 'credit',\n",
       " 'found',\n",
       " 'like',\n",
       " 'onlin',\n",
       " 'cours',\n",
       " 'particip',\n",
       " 'share',\n",
       " 'experi',\n",
       " 'onlin',\n",
       " 'group',\n",
       " 'like',\n",
       " 'look',\n",
       " 'forward',\n",
       " 'get',\n",
       " 'know',\n",
       " 'love',\n",
       " 'bless',\n",
       " 'crose']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dictionary object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA needs a dictionary object, a mapping between words and numeric ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.corpora.dictionary.Dictionary"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turn our tokenized documents into a id <-> term dictionary\n",
    "dictionary = corpora.Dictionary(norm_texts)\n",
    "type(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving the dictionary object to be used later.\n",
    "dictionary.save(utils.data_path+'lda/lda_dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading existing disctionary object.\n",
    "dictionary = corpora.Dictionary.load(utils.data_path+'lda/lda_dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BOW object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with our dictionary, we have to create a bag-of-words object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23838"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tokenized documents into a document-term matrix\n",
    "bows = [dictionary.doc2bow(text) for text in norm_texts]\n",
    "len(bows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of a bag-of-words element (id of word, frequency in sentence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1),\n",
       " (10, 1),\n",
       " (11, 1),\n",
       " (12, 1),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (18, 2),\n",
       " (19, 1),\n",
       " (20, 1),\n",
       " (21, 1),\n",
       " (22, 1),\n",
       " (23, 2),\n",
       " (24, 1),\n",
       " (25, 1),\n",
       " (26, 1),\n",
       " (27, 1),\n",
       " (28, 1),\n",
       " (29, 1),\n",
       " (30, 1),\n",
       " (31, 2),\n",
       " (32, 1),\n",
       " (33, 2),\n",
       " (34, 1),\n",
       " (35, 1),\n",
       " (36, 2),\n",
       " (37, 1),\n",
       " (38, 1),\n",
       " (39, 1),\n",
       " (40, 1),\n",
       " (41, 2),\n",
       " (42, 1),\n",
       " (43, 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bows[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying different parameters, we found that using 10 topics gives us results that make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.035*\"get\" + 0.027*\"cours\" + 0.022*\"student\" + 0.018*\"take\" + 0.018*\"even\" + 0.017*\"submit\" + 0.017*\"respons\" + 0.017*\"start\" + 0.016*\"help\" + 0.015*\"question\"'),\n",
       " (1,\n",
       "  '0.023*\"0\" + 0.019*\"1\" + 0.019*\"3\" + 0.016*\"featur\" + 0.015*\"peer\" + 0.014*\"2\" + 0.011*\"pass\" + 0.011*\"hw4\" + 0.011*\"4\" + 0.011*\"10\"'),\n",
       " (2,\n",
       "  '0.043*\"video\" + 0.032*\"1\" + 0.029*\"2\" + 0.027*\"http\" + 0.025*\"com\" + 0.024*\"error\" + 0.019*\"submiss\" + 0.017*\"youtub\" + 0.017*\"post\" + 0.015*\"time\"'),\n",
       " (3,\n",
       "  '0.035*\"write\" + 0.016*\"read\" + 0.016*\"english\" + 0.016*\"homework\" + 0.014*\"fullnam\" + 0.013*\"m\" + 0.013*\"book\" + 0.012*\"s\" + 0.012*\"cours\" + 0.012*\"sentenc\"'),\n",
       " (4,\n",
       "  '0.019*\"peopl\" + 0.009*\"one\" + 0.009*\"use\" + 0.009*\"children\" + 0.009*\"can\" + 0.009*\"will\" + 0.008*\"problem\" + 0.008*\"mani\" + 0.008*\"countri\" + 0.008*\"world\"'),\n",
       " (5,\n",
       "  '0.043*\"movi\" + 0.028*\"public\" + 0.018*\"us\" + 0.015*\"govern\" + 0.013*\"select\" + 0.011*\"rate\" + 0.011*\"world\" + 0.010*\"servic\" + 0.010*\"rest\" + 0.010*\"internet\"'),\n",
       " (6,\n",
       "  '0.016*\"v\" + 0.012*\"one\" + 0.011*\"s\" + 0.009*\"exampl\" + 0.009*\"apolog\" + 0.009*\"end\" + 0.008*\"guess\" + 0.008*\"mother\" + 0.008*\"say\" + 0.007*\"depend\"'),\n",
       " (7,\n",
       "  '0.025*\"t\" + 0.022*\"thank\" + 0.021*\"can\" + 0.016*\"answer\" + 0.014*\"question\" + 0.013*\"cours\" + 0.013*\"use\" + 0.012*\"pleas\" + 0.011*\"m\" + 0.011*\"week\"'),\n",
       " (8,\n",
       "  '0.029*\"happi\" + 0.016*\"feel\" + 0.014*\"can\" + 0.013*\"peopl\" + 0.013*\"life\" + 0.012*\"think\" + 0.012*\"t\" + 0.010*\"s\" + 0.010*\"make\" + 0.009*\"person\"'),\n",
       " (9,\n",
       "  '0.019*\"rb\" + 0.017*\"certif\" + 0.016*\"essay\" + 0.013*\"t\" + 0.013*\"follow\" + 0.012*\"caus\" + 0.012*\"fatal\" + 0.011*\"draft\" + 0.010*\"exist\" + 0.009*\"key\"')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(bows, num_topics=10, id2word = dictionary, passes=20)\n",
    "ldamodel.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel.save(utils.data_path+'lda/lda_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.LdaModel.load(utils.data_path+'lda/lda_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the model in old and new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a list of (topic, question) for each question in our data set, using the most probable topic. We also use this to infer the topic of a complete new question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_topic_pars(pars, ldamodel, word_dictionary):\n",
    "    norm_pars = [utils.tokenize_and_stem(par) for par in pars]\n",
    "    print('created normalized paragraphs object of length %d' % len(norm_pars))\n",
    "    bows = [word_dictionary.doc2bow(text) for text in norm_pars]\n",
    "    print('created bag-of-words object of length %d' % len(bows))\n",
    "    topic_pars = []\n",
    "    for idx, val in enumerate(bows):\n",
    "        lda_vector = ldamodel[val]\n",
    "        #original LDA model topic (most relevant) and paragraph:\n",
    "        topic_pars.append([ldamodel.print_topic(max(lda_vector, key=lambda item: item[1])[0]), pars[idx]]) #we attach the original paragraph here, not the cleaned version that we used for LDA.\n",
    "    return(topic_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created normalized paragraphs object of length 23838\n",
      "created bag-of-words object of length 23838\n"
     ]
    }
   ],
   "source": [
    "topic_pars = create_topic_pars(questions, ldamodel, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of the topic of an existing question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.025*\"t\" + 0.022*\"thank\" + 0.021*\"can\" + 0.016*\"answer\" + 0.014*\"question\" + 0.013*\"cours\" + 0.013*\"use\" + 0.012*\"pleas\" + 0.011*\"m\" + 0.011*\"week\"',\n",
       " \"Hello.I submitted my solution to HW1 and the auto grader runs some tests for 'invalid' guesses. I have logic in my hangperson_game.rb file that sets a instance variable '@valid' to either true or false. How does the autograder expect the sinatra app to behave when given an invalid guess?Thanks for your help<<FULLNAME>>\\n\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_pars[23000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try with some complete new questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_questions = ['hey, i really think we should get more time to answer the questions in our quizzes, this sucks!!! :((()))', 'I am really sad, dont know how im going to be happy again, anyone knows?', 'is there anyway i can improve my grammar online?', 'I really did not understand the difference between mean and median, anyone who can help me!!!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created normalized paragraphs object of length 4\n",
      "created bag-of-words object of length 4\n"
     ]
    }
   ],
   "source": [
    "new_topic_pars = create_topic_pars(new_questions, ldamodel, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0.019*\"peopl\" + 0.009*\"one\" + 0.009*\"use\" + 0.009*\"children\" + 0.009*\"can\" + 0.009*\"will\" + 0.008*\"problem\" + 0.008*\"mani\" + 0.008*\"countri\" + 0.008*\"world\"',\n",
       "  'hey, i really think we should get more time to answer the questions in our quizzes, this sucks!!! :((()))'],\n",
       " ['0.029*\"happi\" + 0.016*\"feel\" + 0.014*\"can\" + 0.013*\"peopl\" + 0.013*\"life\" + 0.012*\"think\" + 0.012*\"t\" + 0.010*\"s\" + 0.010*\"make\" + 0.009*\"person\"',\n",
       "  'I am really sad, dont know how im going to be happy again, anyone knows?'],\n",
       " ['0.035*\"write\" + 0.016*\"read\" + 0.016*\"english\" + 0.016*\"homework\" + 0.014*\"fullnam\" + 0.013*\"m\" + 0.013*\"book\" + 0.012*\"s\" + 0.012*\"cours\" + 0.012*\"sentenc\"',\n",
       "  'is there anyway i can improve my grammar online?'],\n",
       " ['0.029*\"happi\" + 0.016*\"feel\" + 0.014*\"can\" + 0.013*\"peopl\" + 0.013*\"life\" + 0.012*\"think\" + 0.012*\"t\" + 0.010*\"s\" + 0.010*\"make\" + 0.009*\"person\"',\n",
       "  'I really did not understand the difference between mean and median, anyone who can help me!!!']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_topic_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly an english grammar question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.035*\"write\" + 0.016*\"read\" + 0.016*\"english\" + 0.016*\"homework\" + 0.014*\"fullnam\" + 0.013*\"m\" + 0.013*\"book\" + 0.012*\"s\" + 0.012*\"cours\" + 0.012*\"sentenc\"',\n",
       " 'is there anyway i can improve my grammar online?']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_topic_pars[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the answers to questions on our dataset with the same topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar_answers = [topic_par for topic_par in topic_pars if topic_par[0] == new_topic_pars[2][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1358"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grammar_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0.035*\"write\" + 0.016*\"read\" + 0.016*\"english\" + 0.016*\"homework\" + 0.014*\"fullnam\" + 0.013*\"m\" + 0.013*\"book\" + 0.012*\"s\" + 0.012*\"cours\" + 0.012*\"sentenc\"',\n",
       "  'Dependent clauses go first:1. Because Marina and Tolya arrived at the airport before noon, I did not see them there.2. Because he slept during the day, Nick had problems to fall asleep at night.3. After they left the hotel room, Nick and <<FULLNAME>> realized that they forgot the keys insideIndependent clauses go first:1. The astronaut said that people will live on other planets someday.2. I love to drink coffee because it gives me energy in the morning.3. This assignment is easy if you have taken grammar course.\\n'],\n",
       " ['0.035*\"write\" + 0.016*\"read\" + 0.016*\"english\" + 0.016*\"homework\" + 0.014*\"fullnam\" + 0.013*\"m\" + 0.013*\"book\" + 0.012*\"s\" + 0.012*\"cours\" + 0.012*\"sentenc\"',\n",
       "  'I found this type of advise very useful.  I try to listen as much English in movies, especially the ones I love and from there I get ideas and vocabulary needed.\\n'],\n",
       " ['0.035*\"write\" + 0.016*\"read\" + 0.016*\"english\" + 0.016*\"homework\" + 0.014*\"fullnam\" + 0.013*\"m\" + 0.013*\"book\" + 0.012*\"s\" + 0.012*\"cours\" + 0.012*\"sentenc\"',\n",
       "  'Hi! I am <<FULLNAME>> From Costa Rica, I hope improve on my English. Thanks for this opportunity!Regards for all!\\n']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_answers[502:505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
