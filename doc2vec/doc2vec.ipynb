{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import sys\n",
    "sys.path.append('/research/edubot/repo/edubot/utils/')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will create a Doc2Vec model base on our questions and answers dataset to find similar questions and answers to new questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We'll need an object with questions and label like SENT_#number_of_question.\n",
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "    def __iter__(self):\n",
    "        for uid, line in enumerate(open(utils.data_path + 'doc2vec/' + self.filename, 'r')):\n",
    "            yield LabeledSentence(words=line.split(), tags=['SENT_%s' % uid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.LabeledLineSentence"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_sentense = LabeledLineSentence('questions.txt')\n",
    "type(question_sentense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec(size=100, window=10, min_count=5, workers=5,alpha=0.025, min_alpha=0.025) # use fixed learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(utils.data_path+'doc2vec/doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.doc2vec.Doc2Vec"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Doc2Vec.load(utils.data_path+'doc2vec/doc2vec.model')\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.build_vocab(question_sentense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for epoch in range(10):\n",
    "#    model.train(question_sentense)\n",
    "#    model.alpha -= 0.002  # decrease the learning rate\n",
    "#    model.min_alpha = model.alpha  # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model on existing questions/words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at some similar sentences to the one labeled SENT_0 (first question):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SENT_1', 0.988574206829071), ('SENT_10406', 0.43401357531547546), ('SENT_19487', 0.3859889507293701), ('SENT_6306', 0.3819279074668884), ('SENT_5421', 0.3793574571609497), ('SENT_5426', 0.3752645254135132), ('SENT_5425', 0.3752085268497467), ('SENT_4804', 0.36838746070861816), ('SENT_201', 0.36440780758857727), ('SENT_20527', 0.35341769456863403)]\n"
     ]
    }
   ],
   "source": [
    "print (model.docvecs.most_similar('SENT_0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try with an existing question in the form of a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('why', 0.4441051185131073), (\"I'll\", 0.42746639251708984), ('Any', 0.4150758385658264), ('Hello!My', 0.4144468605518341), ('Anyone', 0.4095126688480377), ('yeh....would', 0.40084922313690186), ('please.', 0.3923271596431732), ('i', 0.38553935289382935), ('skewed', 0.37819305062294006), ('my', 0.3708469569683075)]\n"
     ]
    }
   ],
   "source": [
    "print (model.most_similar('how is the exam going to be graded'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with a common question word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('what', 0.5978665351867676), ('How', 0.5137122869491577), ('why', 0.49313122034072876), ('whether', 0.4372948408126831), ('if', 0.4111274480819702), ('15,531.00.The', 0.38539761304855347), ('boring.*I', 0.38303035497665405), (\"'not\", 0.3646056652069092), (':)<<FULLNAME>>', 0.3630005717277527), ('this,', 0.3546842336654663)]\n"
     ]
    }
   ],
   "source": [
    "print (model.most_similar('how'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most similar function only works with questions that have words in our vocabulary. It will not work newly created question. We'll have to try a different approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WM distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the WM distance mesurement to find similarities between completly new questions, ones that may contain words that are not in our trained vocabulary, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['obama', 'speaks', 'media', 'illinois']\n",
      "['president', 'greets', 'press', 'chicago']\n"
     ]
    }
   ],
   "source": [
    "sentence_obama = utils.tokenize_only('Obama speaks to the media in Illinois')\n",
    "sentence_president = utils.tokenize_only('The president greets the press in Chicago')\n",
    "print(sentence_obama)\n",
    "print(sentence_president)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4614712543673516"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wmdistance(sentence_obama, sentence_president)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see if the distance improves with stemmed sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_obama = utils.tokenize_and_stem('Obama speaks to the media in Illinois')\n",
    "norm_president = utils.tokenize_and_stem('The president greets the press in Chicago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['obama', 'speak', 'media', 'illinoi']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_obama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.261510692152023"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wmdistance(norm_obama, norm_president)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the distance improves. The only issue is that in the process of stemming we could be losing valuable information, stemming can map words like _what_, _why_ and _where_ to the same root, or loose the differences between big and bigest, which can change our related answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given a new question, returns the existing question that has the minimun wm distance to the new one.\n",
    "def get_min_wm_distance(model, new_text, old_texts):\n",
    "    norm_new_text = utils.tokenize_only(new_text)\n",
    "    min_distance = float('inf')\n",
    "    md_text = ''\n",
    "    for old_text in old_texts:\n",
    "        norm_old_text = utils.tokenize_only(old_text)\n",
    "        distance = model.wmdistance(norm_new_text, norm_old_text)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            md_text = old_text\n",
    "    return(min_distance, md_text)\n",
    "\n",
    "#Given a new question, returns the all the existing question with the wm distance to the new one.\n",
    "def get_min_wm_distance_list(model, new_text, old_texts):\n",
    "    norm_new_text = utils.tokenize_only(new_text)\n",
    "    distances = [(model.wmdistance(norm_new_text, utils.tokenize_only(old_text)), old_text) for old_text in old_texts]\n",
    "    return sorted(distances, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi, I am <<FULLNAME>> <<FULLNAME>>.  I am a retired medical worker living in East Tennessee near the Smokey Mountains.  I have an abiding interest in all things spiritual and psychological.  I am also an InterFaith minister, that never really practiced that profession except among my friends.  A close friend is also doing this course for her social worker credits which is how I found out about it.  I like doing online courses where the participants share their experiences in an online group like this.  Looking forward to getting to know you all. Love and blessings,  CRose\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(utils.data_path+'doc2vec/questions.txt', 'r')\n",
    "questions = file.readlines()\n",
    "file.close()\n",
    "questions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see which is the most similar question to _how is the exam going to be graded_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3410407172882863,\n",
       " 'actually i got lost with the way this course is going on,and i want to know how am going to be graded.\\n')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = get_min_wm_distance(model, 'how is the exam going to be graded', questions)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a look at the first 3 most similar questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.3410407172882863,\n",
       "  'actually i got lost with the way this course is going on,and i want to know how am going to be graded.\\n'),\n",
       " (1.4537153441390562, 'major echo going on and talking over each other.\\n'),\n",
       " (1.4816835585840877, 'when are we going to start with week 3?\\n')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = get_min_wm_distance_list(model, 'how is the exam going to be graded', questions)\n",
    "distances[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at several questions ranging from course subjects to general ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8805966358289719, 'Is the grammar important for English writing?\\n')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = get_min_wm_distance(model, 'I am looking for English Grammar resources', questions)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1093645755827917, 'What is the end date of this course?\\n')\n"
     ]
    }
   ],
   "source": [
    "print(get_min_wm_distance(model, 'What date is it today?', questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.157503132306017, 'Is this Course work?\\n')\n"
     ]
    }
   ],
   "source": [
    "print(get_min_wm_distance(model, 'What topics are covered in this course', questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1739545934280706, 'i am forma spa in and this is my first course\\n')\n"
     ]
    }
   ],
   "source": [
    "print(get_min_wm_distance(model, 'how many assignments does this course have?', questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7431855046505927, 'i am forma spa in and this is my first course\\n')\n"
     ]
    }
   ],
   "source": [
    "print(get_min_wm_distance(model, 'how  long is this course?', questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0471347683698653, 'Does anyone have a citation for the study that showed humou is important?\\n')\n"
     ]
    }
   ],
   "source": [
    "print(get_min_wm_distance(model, 'Anyone want to form a study group', questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0817537307739258, 'i am forma spa in and this is my first course\\n')\n"
     ]
    }
   ],
   "source": [
    "print(get_min_wm_distance(model, 'How is this course graded?', questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the answers to the above questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file 1 of 31 \n",
      "reading file 2 of 31 \n",
      "reading file 3 of 31 \n",
      "reading file 4 of 31 \n",
      "reading file 5 of 31 \n",
      "reading file 6 of 31 \n",
      "reading file 7 of 31 \n",
      "reading file 8 of 31 \n",
      "reading file 9 of 31 \n",
      "reading file 10 of 31 \n",
      "reading file 11 of 31 \n",
      "reading file 12 of 31 \n",
      "reading file 13 of 31 \n",
      "reading file 14 of 31 \n",
      "reading file 15 of 31 \n",
      "reading file 16 of 31 \n",
      "reading file 17 of 31 \n",
      "reading file 18 of 31 \n",
      "reading file 19 of 31 \n",
      "reading file 20 of 31 \n",
      "reading file 21 of 31 \n",
      "reading file 22 of 31 \n",
      "reading file 23 of 31 \n",
      "reading file 24 of 31 \n",
      "reading file 25 of 31 \n",
      "reading file 26 of 31 \n",
      "reading file 27 of 31 \n",
      "reading file 28 of 31 \n",
      "reading file 29 of 31 \n",
      "reading file 30 of 31 \n",
      "reading file 31 of 31 \n",
      "42754 question threads in the data\n",
      "23838 answer threads in the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/research/edubot/repo/edubot/utils/utils.py:59: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  all_qa = all_qa.sort(['_id.$oid_q', 'comment_thread_id.$oid'])\n"
     ]
    }
   ],
   "source": [
    "qa_all = utils.get_qa_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_q</th>\n",
       "      <th>body_q</th>\n",
       "      <th>author_id_q</th>\n",
       "      <th>course_id_q</th>\n",
       "      <th>_id.$oid_q</th>\n",
       "      <th>parent_id.$oid</th>\n",
       "      <th>title_a</th>\n",
       "      <th>body_a</th>\n",
       "      <th>author_id_a</th>\n",
       "      <th>course_id_a</th>\n",
       "      <th>_id.$oid_a</th>\n",
       "      <th>comment_thread_id.$oid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52504</th>\n",
       "      <td>Hi from Spain</td>\n",
       "      <td>I'm pharmacist and I want to do this course to...</td>\n",
       "      <td>588608143</td>\n",
       "      <td>BerkeleyX/GG101x/1T2014</td>\n",
       "      <td>5408bf5b1df0baf15900000c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52503</th>\n",
       "      <td>Hello</td>\n",
       "      <td>I have just registered for the course and am a...</td>\n",
       "      <td>570428032</td>\n",
       "      <td>BerkeleyX/GG101x/1T2014</td>\n",
       "      <td>5408c2f11df0bac5fb0000ce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52501</th>\n",
       "      <td>Introduction</td>\n",
       "      <td>Hi, I am &lt;&lt;FULLNAME&gt;&gt; &lt;&lt;FULLNAME&gt;&gt;.  I am a re...</td>\n",
       "      <td>691432080</td>\n",
       "      <td>BerkeleyX/GG101x/1T2014</td>\n",
       "      <td>5408d3c89bb11c6fb5000019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cheryl Rose, I am living in Knoxville. I am a ...</td>\n",
       "      <td>704734742</td>\n",
       "      <td>BerkeleyX/GG101x/1T2014</td>\n",
       "      <td>540c6c949bb11c4b480000f1</td>\n",
       "      <td>5408d3c89bb11c6fb5000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52502</th>\n",
       "      <td>Introduction</td>\n",
       "      <td>Hi, I am &lt;&lt;FULLNAME&gt;&gt; &lt;&lt;FULLNAME&gt;&gt;.  I am a re...</td>\n",
       "      <td>691432080</td>\n",
       "      <td>BerkeleyX/GG101x/1T2014</td>\n",
       "      <td>5408d3c89bb11c6fb5000019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello from Toronto</td>\n",
       "      <td>3439105</td>\n",
       "      <td>BerkeleyX/GG101x/1T2014</td>\n",
       "      <td>5408f8991df0babbb1000016</td>\n",
       "      <td>5408d3c89bb11c6fb5000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52499</th>\n",
       "      <td>Greetings from the Northwest U.S.</td>\n",
       "      <td>Hello! I live in a small town near the U.S./Ca...</td>\n",
       "      <td>85357777</td>\n",
       "      <td>BerkeleyX/GG101x/1T2014</td>\n",
       "      <td>5408d89f1df0baaff0000015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Greetings, Sister Northwesterner! I live over ...</td>\n",
       "      <td>538343067</td>\n",
       "      <td>BerkeleyX/GG101x/1T2014</td>\n",
       "      <td>5409ce0b9bb11ccfc2000007</td>\n",
       "      <td>5408d89f1df0baaff0000015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title_q  \\\n",
       "52504                      Hi from Spain   \n",
       "52503                              Hello   \n",
       "52501                       Introduction   \n",
       "52502                       Introduction   \n",
       "52499  Greetings from the Northwest U.S.   \n",
       "\n",
       "                                                  body_q author_id_q  \\\n",
       "52504  I'm pharmacist and I want to do this course to...   588608143   \n",
       "52503  I have just registered for the course and am a...   570428032   \n",
       "52501  Hi, I am <<FULLNAME>> <<FULLNAME>>.  I am a re...   691432080   \n",
       "52502  Hi, I am <<FULLNAME>> <<FULLNAME>>.  I am a re...   691432080   \n",
       "52499  Hello! I live in a small town near the U.S./Ca...    85357777   \n",
       "\n",
       "                   course_id_q                _id.$oid_q parent_id.$oid  \\\n",
       "52504  BerkeleyX/GG101x/1T2014  5408bf5b1df0baf15900000c            NaN   \n",
       "52503  BerkeleyX/GG101x/1T2014  5408c2f11df0bac5fb0000ce            NaN   \n",
       "52501  BerkeleyX/GG101x/1T2014  5408d3c89bb11c6fb5000019            NaN   \n",
       "52502  BerkeleyX/GG101x/1T2014  5408d3c89bb11c6fb5000019            NaN   \n",
       "52499  BerkeleyX/GG101x/1T2014  5408d89f1df0baaff0000015            NaN   \n",
       "\n",
       "      title_a                                             body_a author_id_a  \\\n",
       "52504     NaN                                                NaN         NaN   \n",
       "52503     NaN                                                NaN         NaN   \n",
       "52501     NaN  Cheryl Rose, I am living in Knoxville. I am a ...   704734742   \n",
       "52502     NaN                                 Hello from Toronto     3439105   \n",
       "52499     NaN  Greetings, Sister Northwesterner! I live over ...   538343067   \n",
       "\n",
       "                   course_id_a                _id.$oid_a  \\\n",
       "52504                      NaN                       NaN   \n",
       "52503                      NaN                       NaN   \n",
       "52501  BerkeleyX/GG101x/1T2014  540c6c949bb11c4b480000f1   \n",
       "52502  BerkeleyX/GG101x/1T2014  5408f8991df0babbb1000016   \n",
       "52499  BerkeleyX/GG101x/1T2014  5409ce0b9bb11ccfc2000007   \n",
       "\n",
       "         comment_thread_id.$oid  \n",
       "52504                       NaN  \n",
       "52503                       NaN  \n",
       "52501  5408d3c89bb11c6fb5000019  \n",
       "52502  5408d3c89bb11c6fb5000019  \n",
       "52499  5408d89f1df0baaff0000015  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'The following link may help you to understand the importance of grammar.\\n\\nhttp://grammar.about.com/od/grammarfaq/f/grammarvalue.htm'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_all[qa_all['body_q'] == 'Is the grammar important for English writing?']['body_a'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
